{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Despliegue entorno Hadoop\n",
    "\n",
    "## Big Data Aplicado\n",
    "\n",
    "## David Carlón Cembranos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta tarea es que despliegues el entorno de Hadoop que vamos a usar en el resto de unidades. Para ello debes realizar paso a paso el proceso que se explicó en la guía práctica. Después podrás entregar esta plantilla sustituyendo las celdas de markdown o de código por lo que se pide. Lee detenidamente el enunciado ya que a veces se pedirá que incluyas una imagen, otras texto y en algunas código ejecutable. El libro de Jupyter que entregues deberá tener las celdas completamente ejecutadas en orden secuencial, no debe tener errores y corresponderá con la ejecución real que obtuviste al ejecutarlo en el contenedor `namenode` de tu equipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comienza copiando este libro, `Tarea\\ para\\ BDA01.ipynb`, en el servidor de Jupyter. Recuerda que el directorio `notebooks` del anfitrión está montado en el directorio `/media/notebooks` del contenedor llamado `namenode` de `docker`. Cualquier cosa que sitúes en este directorio (o en un subdirectorio) será accesible tanto por el anfitrión como por el contenedor.\n",
    "\n",
    "Si el anterior párrafo no tiene sentido para ti, probablemente debas revisar de nuevo la guía práctica antes de seguir con la tarea práctica.\n",
    "\n",
    "Es posible que al intentar copiar el libro `Tarea\\ para\\ BDA01.ipynb` tengas un problema de permisos. Si esto sucede es porque el contenedor de `docker` está asignando la propiedad de los archivos al usuario `root`. Este problema se puede solucionar de distintas formas:\n",
    "\n",
    "* Asignando permisos de escritura a todos los usuarios (comando `chmod` en Linux).\n",
    "* Usando el comando `sudo`.\n",
    "* Copiando el archivo desde el anfitrión al contenedor con el comando `cp` de `docker`:\n",
    "```bash\n",
    "docker cp Tarea\\ para\\ BDA01.ipynb namenode:/media/notebooks/unidad\\ 1/\n",
    "```\n",
    "* Si todo lo anterior no funciona, pregunta en el foro.\n",
    "\n",
    "Una vez tengas la plantilla de la tarea en el servidor de Jupyter, comienza a completar las celdas que empiecen por \"TODO\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Instala `docker` y `docker-compose` en tu equipo y copia una imagen en la que se muestre el resultado de ejecutar en el anfitrión las siguientes instrucciones:\n",
    "\n",
    "```bash\n",
    "docker --version\n",
    "docker-compose --version\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pantallazo de mi version de docker y docker-compose\n",
    "\n",
    "![docker version](./img/dockerversion.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Levanta el entorno de Hadoop con `docker-compose` haciendo lo que se indica en la guía práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando que se utiliza para iniciar hadoop es el siguiente:\n",
    "\n",
    "`docker-compose -f hadoop.yml up`\n",
    "\n",
    "Pantallazo del inicio de hadoop en el equipo anfitrión.\n",
    "\n",
    "![docker-compose up](./img/levantarhaddop.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Muestra en Jupyter el contenido del directorio en el que estás ejecutando este libro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![jupyter listado](./img/jupyter.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.- Realiza todo el proceso que se describe en la guía práctica para obtener el número de palabras que contiene *El Quijote*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comando de descarga del quijote dentro de contenedor creando una carpeta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-12 17:42:33--  https://www.gutenberg.org/files/2000/2000-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2226045 (2.1M) [text/plain]\n",
      "Saving to: ‘libroquijote/2000-0.txt’\n",
      "\n",
      "2000-0.txt          100%[===================>]   2.12M  2.09MB/s    in 1.0s    \n",
      "\n",
      "2023-12-12 17:42:45 (2.09 MB/s) - ‘libroquijote/2000-0.txt’ saved [2226045/2226045]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -P 'libroquijote' https://www.gutenberg.org/files/2000/2000-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('libroquijote/2000-0.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38062"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El Quijote tiene 383640 palabras aproximadamente.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = 24\n",
    "tail = 360\n",
    "\n",
    "book = lines[head:-tail]\n",
    "book = ''.join(book)\n",
    "book = book.lower()\n",
    "\n",
    "import re\n",
    "\n",
    "book = re.split('\\W+', book)\n",
    "\n",
    "list(filter(lambda word: len(word) == 0, book))\n",
    "book = list(filter(lambda word: len(word), book))\n",
    "book[0:10]\n",
    "'El Quijote tiene {} palabras aproximadamente.'.format(len(book))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.- Crea un proceso en Python que muestre las 10 palabras que más se utilizan en *El Quijote* junto con el número de veces que aparecen en el libro.\n",
    "\n",
    "Los ejercicios anteriores pretendían simplemente que replicaras el trabajo que se realizó en la guía práctica. Este ejercicio tiene como objetivo que empieces a crear tus primeros programas en Python para que te resulten más fáciles las próximas prácticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "que: 20769\n",
      "de: 18410\n",
      "y: 18272\n",
      "la: 10492\n",
      "a: 9876\n",
      "en: 8285\n",
      "el: 8265\n",
      "no: 6346\n",
      "los: 4769\n",
      "se: 4752\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Lee el texto de El Quijote desde el archivo, excluyendo las primeras 24 líneas y las últimas 360 líneas\n",
    "file_path = 'libroquijote/2000-0.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    quijote_text = ''.join(lines[24:-360])\n",
    "\n",
    "# Tokeniza el texto en palabras\n",
    "words = re.findall(r'\\b\\w+\\b', quijote_text.lower())  # Convierte a minúsculas y tokeniza\n",
    "\n",
    "# Cuenta la frecuencia de cada palabra\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Obtiene las 10 palabras más comunes\n",
    "top_words = dict(sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "# Imprime las 10 palabras más comunes junto con su frecuencia\n",
    "for word, count in top_words.items():\n",
    "    print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.- (OPCIONAL) Los dos últimos ejercicios son tareas habituales en el mundo de Big Data, concretamente pertenecen a un área denominada Procesamiento de Lenguaje Natural (NLP). Sin embargo, la solución que se pidió es trivial y tiene bastantes problemas para ser aplicada en un entorno profesional:\n",
    "\n",
    "* Por un lado no admite trabajar con un gran volumen de datos. De esto nos ocuparemos en próximas prácticas ya que este es el problema esencial al que tratamos de dar solución en este módulo.\n",
    "* Por otro, tanto la división en palabras (ejercicio 4), como el cálculo de la frecuencia de aparición (ejercicio 5), hacen suposiciones poco realistas: Para la división en palabras hemos supuesto que cualquier carácter no alfanumérico sirve para separar dos palabras, pero esto no es siempre cierto. Por ejemplo, ¿cuántas palabras hay en O.T.A.N.?, ¿cinco o una? Además, para contar las palabras más frecuentes no hemos tenido en cuenta que una misma palabra se puede presentar en diferentes formas. Por ejemplo: \"la\" y \"las\", ¿son la misma palabra o dos palabras diferentes?, ¿y \"fue\" e \"irá\"? La respuesta a esta pregunta no es unívoca y dependerá del objetivo del estudio.\n",
    "\n",
    "Las herramientas de NLP nos permiten tanto dividir un texto en palabras (\"tokenization\"), como \n",
    "obtener el [lema](https://es.wikipedia.org/wiki/Lema_(ling%C3%BC%C3%ADstica)#:~:text=El%20lema%20es%20la%20unidad,o%20no%2C%20de%20un%20lema.) de una palabra (\"lemmatisation\"). En este ejercicio se pretende que resuelvas los ejercicios 4 y 5 usando [`spaCy`](https://spacy.io/), que es una herramienta NLP popular en el mundo Python. Dado que se trata de una actividad voluntaria y para hacerlo más interesante, no se va a dar ninguna indicación de cómo realizar el proceso. Incluso aunque no llegues a resolver el ejercicio, es interesante que consultes la solución cuando esta se publique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.7.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (45.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: numpy>=1.15.0; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from spacy) (1.24.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from spacy) (2.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: confection<0.2.0,>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.1.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: es-core-news-sm==3.7.0 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl in /usr/local/lib/python3.8/dist-packages (3.7.0)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from es-core-news-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.5.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: numpy>=1.15.0; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.24.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (45.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.9.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.14.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: confection<0.2.0,>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de líneas en El Quijote: 38062\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Cargar el modelo de idioma en español de spaCy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Establecer un nuevo límite de longitud\n",
    "nlp.max_length = 3000000  # Ajusta este valor según sea necesario\n",
    "\n",
    "# Leer el texto de El Quijote desde el archivo, excluyendo las primeras 24 líneas y las últimas 360 líneas\n",
    "file_path = 'libroquijote/2000-0.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    quijote_text = ''.join(lines[24:-360])\n",
    "\n",
    "# Contar las líneas en El Quijote\n",
    "total_lines = len(lines)\n",
    "print(f'Total de líneas en El Quijote: {total_lines}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar el texto con spaCy\n",
    "doc = nlp(quijote_text)\n",
    "\n",
    "# Obtener todas las palabras (sin filtrar)\n",
    "all_words = [token.text.lower() for token in doc if token.is_alpha]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuenta la frecuencia de todas las palabras\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Obtiene las 10 palabras más comunes\n",
    "top_words = dict(word_counts.most_common(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabras más comunes:\n",
      "que: 20769\n",
      "de: 18409\n",
      "y: 18272\n",
      "la: 10492\n",
      "a: 9875\n",
      "en: 8283\n",
      "el: 8265\n",
      "no: 6346\n",
      "los: 4769\n",
      "se: 4752\n",
      "\n",
      "Total de palabras en El Quijote: 383495\n"
     ]
    }
   ],
   "source": [
    "# Imprime las 10 palabras más comunes junto con su frecuencia\n",
    "print(\"\\nPalabras más comunes:\")\n",
    "for word, count in top_words.items():\n",
    "    print(f'{word}: {count}')\n",
    "\n",
    "# Imprime el total de palabras en El Quijote\n",
    "total_words = len(all_words)\n",
    "print(f'\\nTotal de palabras en El Quijote: {total_words}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
