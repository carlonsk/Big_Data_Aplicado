{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plantilla para la Tarea online BDA03\n",
    "\n",
    "# Nombre del alumno: David Carlon Cembranos\n",
    "\n",
    "Realiza las tareas que se plantean en cada ejercicio. En algunas tareas deberás completar las celdas que están incompletas en otras añadir nuevas celdas. Se trata de que implementes una serie de consultas con HQL (Hive) y Pig Latin.\n",
    "\n",
    "Vamos a seguir utilizando el `dataset` de retrasos en vuelos en EEUU de la guía práctica. A modo de recordatorio, en el siguiente apartado, repetimos la explicación del significado de los campos.\n",
    "\n",
    "# Dataset de retrasos en vuelos\n",
    "\n",
    "Vamos a usar [este](https://www.kaggle.com/datasets/tylerx/flights-and-airports-data) de Kaggle\n",
    "para aprender a usar tanto Hive como Pig. Kaggle es un sitio muy popular en ciencia de datos. En este sitio los científicos de datos pueden publicar y compartir sus trabajos. Además también se pueden proponer concursos en los que los participantes compiten en la construcción del mejor modelo para el problema propuesto.\n",
    "\n",
    "El `dataset` contiene información sobre retrasos en vuelos en EEUU. Hay dos ficheros de interés: `airports.csv` y `flights.csv`.\n",
    "\n",
    "El primero tiene información sobre los aeropuertos y consta de los siguientes campos:\n",
    "   * airport_id: identificador del aeropuerto. Numérico, aunque se utilizará un campo `string` en Hive.\n",
    "   * city: ciudad del aeropuerto.\n",
    "   * state: estado del aeropuerto.\n",
    "   * name: nombre del aeropuerto.\n",
    "   \n",
    "El fichero `flights` tiene la siguiente estructura:\n",
    "   * DayofMonth: día del mes del vuelo.\n",
    "   * DayOfWeek: día de la semana del vuelo.\n",
    "   * Carrier: Identificador de la compañía aérea.\n",
    "   * OriginAirportID: Identificador del aeropuerto de origen.\n",
    "   * DestAirportID: Identificador del aeropuerto de destino.\n",
    "   * DepDelay: Minutos de retraso en la salida de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto).\n",
    "   * ArrDelay: Minutos de retraso en la llegada de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto).\n",
    "\n",
    "El directorio `notebooks` contiene el `archiv.zip` con los dos ficheros. Para descargarlo de Kaggle hay que estar registrado y se ha incluido para que no tengas que registrarte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Realiza el proceso de preparación que se hizo en la guia práctica:\n",
    "\n",
    "* Crea las celdas y muestra el resultado de su ejecución de la extracción de los ficheros del `dataset` de vuelos.\n",
    "* Crea la base de datos de Hive y las tablas `airports` y `flights`. Presta atención a cambiar los comentarios y no simplemente copiar los de la guía.\n",
    "* Carga las tablas y crea consultas de HQL que muestren 10 aeropuertos y 10 vuelos como se hizo en la guía práctica.\n",
    "* Crea un `script` en Pig Latin que muestre 10 aeropuertos y 10 vuelos como se hizo en la guía práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease   \u001b[0m\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1176 kB]\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1473 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3372 kB][33m\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3850 kB]m\u001b[33m\n",
      "Fetched 10.1 MB in 4s (2878 kB/s)   \u001b[0m                   \u001b[0m   \u001b[0mm\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "207 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
     ]
    }
   ],
   "source": [
    "! apt update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalamos UNZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-25ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 207 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "! apt install unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraemos los archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  archive.zip\n",
      "  inflating: airports.csv            \n",
      "  inflating: flights.csv             \n"
     ]
    }
   ],
   "source": [
    "! unzip -j  -o archive.zip airports.csv flights.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostramos primeras lineas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702219 flights.csv\r\n",
      "DayofMonth,DayOfWeek,Carrier,OriginAirportID,DestAirportID,DepDelay,ArrDelay\r",
      "\r\n",
      "19,5,DL,11433,13303,-3,1\r",
      "\r\n",
      "19,5,DL,14869,12478,0,-8\r",
      "\r\n",
      "19,5,DL,14057,14869,-4,-15\r",
      "\r\n",
      "19,5,DL,15016,11433,28,24\r",
      "\r\n",
      "19,5,DL,11193,12892,-6,-11\r",
      "\r\n",
      "19,5,DL,10397,15016,-1,-19\r",
      "\r\n",
      "19,5,DL,15016,10397,0,-1\r",
      "\r\n",
      "19,5,DL,10397,14869,15,24\r",
      "\r\n",
      "19,5,DL,10397,10423,33,34\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l flights.csv && head flights.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copiamos ficheros HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 root supergroup      16308 2024-02-15 09:25 /user/root/flights/airports.csv\r\n",
      "-rw-r--r--   3 root supergroup   72088113 2024-02-15 09:25 /user/root/flights/flights.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mkdir -p /user/root/flights\n",
    "! hdfs dfs -put -f ./airports.csv /user/root/flights/\n",
    "! hdfs dfs -put -f ./flights.csv /user/root/flights/\n",
    "! hdfs dfs -ls /user/root/flights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIVE\n",
    "### Mostramos  con beeline si hay bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215092710_01ae206e-7a6b-4f62-b101-147d7df63212): SHOW DATABASES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215092710_01ae206e-7a6b-4f62-b101-147d7df63212); Time taken: 0.712 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215092710_01ae206e-7a6b-4f62-b101-147d7df63212): SHOW DATABASES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215092710_01ae206e-7a6b-4f62-b101-147d7df63212); Time taken: 0.023 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------+\n",
      "| database_name  |\n",
      "+----------------+\n",
      "| bda03          |\n",
      "| default        |\n",
      "+----------------+\n",
      "2 rows selected (0.932 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000\" -e \"SHOW DATABASES\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos una nueva tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215092929_736b8fb5-d27f-4d88-bf70-ad6c20047395): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos para la tarea BDA03'  WITH DBPROPERTIES ('Creada por' = 'David Carlon', 'Fecha' = '15/02/2024')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215092929_736b8fb5-d27f-4d88-bf70-ad6c20047395); Time taken: 0.013 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215092929_736b8fb5-d27f-4d88-bf70-ad6c20047395): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos para la tarea BDA03'  WITH DBPROPERTIES ('Creada por' = 'David Carlon', 'Fecha' = '15/02/2024')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215092929_736b8fb5-d27f-4d88-bf70-ad6c20047395); Time taken: 0.02 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.059 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -e \"\\\n",
    "CREATE DATABASE IF NOT EXISTS bda03 \\\n",
    "COMMENT 'Base de datos para la tarea BDA03' \\\n",
    "WITH DBPROPERTIES ('Creada por' = 'David Carlon', 'Fecha' = '15/02/2024');\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos tablas airportos y flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215093200_44710555-e64c-4f07-aba6-40b512d801b0): DROP TABLE IF EXISTS airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215093200_44710555-e64c-4f07-aba6-40b512d801b0); Time taken: 0.081 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215093200_44710555-e64c-4f07-aba6-40b512d801b0): DROP TABLE IF EXISTS airports\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215093200_44710555-e64c-4f07-aba6-40b512d801b0); Time taken: 0.145 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.253 seconds)\n",
      "INFO  : Compiling command(queryId=root_20240215093200_fa22efdd-40eb-4ef8-9df5-82a1144f93e1): CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING)  COMMENT 'USA Airports'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'David Carlon', 'Fecha' = '15/02/2024', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215093200_fa22efdd-40eb-4ef8-9df5-82a1144f93e1); Time taken: 0.042 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215093200_fa22efdd-40eb-4ef8-9df5-82a1144f93e1): CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING)  COMMENT 'USA Airports'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'David Carlon', 'Fecha' = '15/02/2024', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215093200_fa22efdd-40eb-4ef8-9df5-82a1144f93e1); Time taken: 0.193 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.241 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "DROP TABLE IF EXISTS airports; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING) \\\n",
    "COMMENT 'USA Airports' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autor' = 'David Carlon', 'Fecha' = '15/02/2024', 'skip.header.line.count'='1');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215093249_3f5f072e-2aae-4509-b43d-ca41723b3ef7): DROP TABLE IF EXISTS flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215093249_3f5f072e-2aae-4509-b43d-ca41723b3ef7); Time taken: 0.019 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215093249_3f5f072e-2aae-4509-b43d-ca41723b3ef7): DROP TABLE IF EXISTS flights\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215093249_3f5f072e-2aae-4509-b43d-ca41723b3ef7); Time taken: 0.055 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.098 seconds)\n",
      "INFO  : Compiling command(queryId=root_20240215093249_308a5b19-086f-47f4-9de0-799c7813c250): CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING,      depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT)  COMMENT 'Flights'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'David Carlon', 'Fecha' = '15/02/2024', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215093249_308a5b19-086f-47f4-9de0-799c7813c250); Time taken: 0.015 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215093249_308a5b19-086f-47f4-9de0-799c7813c250): CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING,      depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT)  COMMENT 'Flights'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'David Carlon', 'Fecha' = '15/02/2024', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215093249_308a5b19-086f-47f4-9de0-799c7813c250); Time taken: 0.029 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.053 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "DROP TABLE IF EXISTS flights; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING, \\\n",
    "    depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT) \\\n",
    "COMMENT 'Flights' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autor' = 'David Carlon', 'Fecha' = '15/02/2024', 'skip.header.line.count'='1');\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permisos al directorio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -chmod 777 /user/root/flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215093453_1ad8ebb7-4cc4-42c6-bfe1-5459bddfd308): LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215093453_1ad8ebb7-4cc4-42c6-bfe1-5459bddfd308); Time taken: 0.03 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215093453_1ad8ebb7-4cc4-42c6-bfe1-5459bddfd308): LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.airports from hdfs://namenode:8020/user/root/flights/airports.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215093453_1ad8ebb7-4cc4-42c6-bfe1-5459bddfd308); Time taken: 0.247 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.301 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215093513_0a4583de-26d4-4fc2-ad2f-a5d6997d5942): LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215093513_0a4583de-26d4-4fc2-ad2f-a5d6997d5942); Time taken: 0.019 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215093513_0a4583de-26d4-4fc2-ad2f-a5d6997d5942): LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.flights from hdfs://namenode:8020/user/root/flights/flights.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215093513_0a4583de-26d4-4fc2-ad2f-a5d6997d5942); Time taken: 0.101 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.144 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostramos 10 aeropuertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215093634_f31b8be4-1475-46ab-ada7-01f72d27ce5c): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airports.airportid, type:string, comment:null), FieldSchema(name:airports.city, type:string, comment:null), FieldSchema(name:airports.state, type:string, comment:null), FieldSchema(name:airports.airportname, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215093634_f31b8be4-1475-46ab-ada7-01f72d27ce5c); Time taken: 0.706 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215093634_f31b8be4-1475-46ab-ada7-01f72d27ce5c): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20240215093634_f31b8be4-1475-46ab-ada7-01f72d27ce5c); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "| airports.airportid  | airports.city  | airports.state  |         airports.airportname         |\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "| 10165               | Adak Island    | AK              | Adak                                 |\n",
      "| 10299               | Anchorage      | AK              | Ted Stevens Anchorage International  |\n",
      "| 10304               | Aniak          | AK              | Aniak Airport                        |\n",
      "| 10754               | Barrow         | AK              | Wiley Post/Will Rogers Memorial      |\n",
      "| 10551               | Bethel         | AK              | Bethel Airport                       |\n",
      "| 10926               | Cordova        | AK              | Merle K Mudhole Smith                |\n",
      "| 14709               | Deadhorse      | AK              | Deadhorse Airport                    |\n",
      "| 11336               | Dillingham     | AK              | Dillingham Airport                   |\n",
      "| 11630               | Fairbanks      | AK              | Fairbanks International              |\n",
      "| 11997               | Gustavus       | AK              | Gustavus Airport                     |\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "10 rows selected (0.772 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! ! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT * FROM airports LIMIT 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostramos 10 vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215093710_8317c8b0-e520-4a8a-ae4b-caeadb0b8dd1): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:flights.dayofmonth, type:tinyint, comment:null), FieldSchema(name:flights.dayofweek, type:tinyint, comment:null), FieldSchema(name:flights.carrier, type:string, comment:null), FieldSchema(name:flights.depairportid, type:string, comment:null), FieldSchema(name:flights.arrairportid, type:string, comment:null), FieldSchema(name:flights.depdelay, type:smallint, comment:null), FieldSchema(name:flights.arrdelay, type:smallint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215093710_8317c8b0-e520-4a8a-ae4b-caeadb0b8dd1); Time taken: 0.073 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215093710_8317c8b0-e520-4a8a-ae4b-caeadb0b8dd1): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20240215093710_8317c8b0-e520-4a8a-ae4b-caeadb0b8dd1); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "| flights.dayofmonth  | flights.dayofweek  | flights.carrier  | flights.depairportid  | flights.arrairportid  | flights.depdelay  | flights.arrdelay  |\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "| 19                  | 5                  | DL               | 11433                 | 13303                 | -3                | 1                 |\n",
      "| 19                  | 5                  | DL               | 14869                 | 12478                 | 0                 | -8                |\n",
      "| 19                  | 5                  | DL               | 14057                 | 14869                 | -4                | -15               |\n",
      "| 19                  | 5                  | DL               | 15016                 | 11433                 | 28                | 24                |\n",
      "| 19                  | 5                  | DL               | 11193                 | 12892                 | -6                | -11               |\n",
      "| 19                  | 5                  | DL               | 10397                 | 15016                 | -1                | -19               |\n",
      "| 19                  | 5                  | DL               | 15016                 | 10397                 | 0                 | -1                |\n",
      "| 19                  | 5                  | DL               | 10397                 | 14869                 | 15                | 24                |\n",
      "| 19                  | 5                  | DL               | 10397                 | 10423                 | 33                | 34                |\n",
      "| 19                  | 5                  | DL               | 11278                 | 10397                 | 323               | 322               |\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "10 rows selected (0.131 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT * FROM flights LIMIT 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIG\n",
    "### Mostramos 10 aeropuertos y 10 vuelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile flights.pig\n",
    "\n",
    "-- registramos la librería PiggyBank para poder usar la función de carga CSVExcelStorage.\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "/*\n",
    "Leemos el fichero de airports.csv.\n",
    "Usamos el loader CSVExcelStorage indicando el delimitador (,) y que se debe excluir la cabecera.\n",
    "*/\n",
    "\n",
    "AIRPORTS = LOAD '$airports_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (airportid:chararray, city:chararray, state:chararray, airportname:chararray);\n",
    "\n",
    "-- Leemos el fichero fligths.csv\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (dayofmonth:int, dayofweek:int, carrier:chararray, \n",
    "               depairportid:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "-- Probamos que podemos recuperar datos.\n",
    "      \n",
    "-- Nos quedamos con 10 aeropuertos\n",
    "AIRPORTS_10 = LIMIT AIRPORTS 10;\n",
    "\n",
    "-- Mostramos 10 aeropuertos\n",
    "DUMP AIRPORTS_10;\n",
    "\n",
    "-- Hacemos lo mismo con los vuelos\n",
    "FLIGHTS_10 = LIMIT FLIGHTS 10;\n",
    "DUMP FLIGHTS_10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 09:40:43,738 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-02-15 09:40:43,739 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-02-15 09:40:43,767 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-02-15 09:40:43,767 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/TAREA03/notebooks/pig_1707986443766.log\n",
      "2024-02-15 09:40:43,774 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-02-15 09:40:43,844 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-02-15 09:40:43,878 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 09:40:43,878 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-02-15 09:40:43,889 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-flights.pig-c1a286a5-5d53-4196-a81f-1e021dd8dbd6\n",
      "2024-02-15 09:40:43,889 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-02-15 09:40:44,341 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2024-02-15 09:40:44,366 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-15 09:40:44,402 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 09:40:44,442 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 09:40:44,442 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 09:40:44,476 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 09:40:44,482 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 09:40:44,483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 09:40:44,515 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp-1213534841/tmp-1687942948\n",
      "2024-02-15 09:40:44,519 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 09:40:44,522 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 09:40:44,522 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(10165,Adak Island,AK,Adak)\n",
      "(10299,Anchorage,AK,Ted Stevens Anchorage International)\n",
      "(10304,Aniak,AK,Aniak Airport)\n",
      "(10754,Barrow,AK,Wiley Post/Will Rogers Memorial)\n",
      "(10551,Bethel,AK,Bethel Airport)\n",
      "(10926,Cordova,AK,Merle K Mudhole Smith)\n",
      "(14709,Deadhorse,AK,Deadhorse Airport)\n",
      "(11336,Dillingham,AK,Dillingham Airport)\n",
      "(11630,Fairbanks,AK,Fairbanks International)\n",
      "(11997,Gustavus,AK,Gustavus Airport)\n",
      "2024-02-15 09:40:44,584 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2024-02-15 09:40:44,592 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 09:40:44,592 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-15 09:40:44,602 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 09:40:44,602 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 09:40:44,609 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 09:40:44,614 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 09:40:44,614 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 09:40:44,627 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp-1213534841/tmp1032470434\n",
      "2024-02-15 09:40:44,629 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 09:40:44,630 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 09:40:44,630 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(19,5,DL,11433,13303,-3,1)\n",
      "(19,5,DL,14869,12478,0,-8)\n",
      "(19,5,DL,14057,14869,-4,-15)\n",
      "(19,5,DL,15016,11433,28,24)\n",
      "(19,5,DL,11193,12892,-6,-11)\n",
      "(19,5,DL,10397,15016,-1,-19)\n",
      "(19,5,DL,15016,10397,0,-1)\n",
      "(19,5,DL,10397,14869,15,24)\n",
      "(19,5,DL,10397,10423,33,34)\n",
      "(19,5,DL,11278,10397,323,322)\n",
      "2024-02-15 09:40:44,655 [main] INFO  org.apache.pig.Main - Pig script completed in 993 milliseconds (993 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Con una consulta de HQL muestra: La cinco compañías que más vuelos retrasados tienen.\n",
    "\n",
    "* El campo `carrier` contiene la compañía aérea.\n",
    "* Vamos a considerar que un vuelo llega con retraso cuando el vuelo llega más de 15 minutos tarde (campo `arrdelay` > 15).\n",
    "\n",
    "Se espera el siguiente resultado:\n",
    "\n",
    "![solución 2](./img/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizamos beeline para conectar con la base de datos de Hive \"bda03\". Ejecutamos la consulta que selecciona la compañia aerea y cuenta los vuelos retrasados de llegada con mas de 15 minutos. Ordemos los resultados segun el nuemro de vuelos retrasados y mostramos las 5 compañias con mas vuelos retrasados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215095526_416ca2e5-74aa-4176-a789-25d7af248d5b): SELECT carrier, COUNT(*) as delayed_flights FROM flights WHERE arrdelay > 15 GROUP BY carrier  ORDER BY delayed_flights DESC LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:carrier, type:string, comment:null), FieldSchema(name:delayed_flights, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215095526_416ca2e5-74aa-4176-a789-25d7af248d5b); Time taken: 0.102 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215095526_416ca2e5-74aa-4176-a789-25d7af248d5b): SELECT carrier, COUNT(*) as delayed_flights FROM flights WHERE arrdelay > 15 GROUP BY carrier  ORDER BY delayed_flights DESC LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20240215095526_416ca2e5-74aa-4176-a789-25d7af248d5b\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1707982394014_0005\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1707982394014_0005/\n",
      "INFO  : Starting Job = job_1707982394014_0005, Tracking URL = http://yarnmaster:8088/proxy/application_1707982394014_0005/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1707982394014_0005\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-15 09:55:29,899 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-15 09:55:34,981 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.67 sec\n",
      "INFO  : 2024-02-15 09:55:39,042 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.96 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 960 msec\n",
      "INFO  : Ended Job = job_1707982394014_0005\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1707982394014_0006\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1707982394014_0006/\n",
      "INFO  : Starting Job = job_1707982394014_0006, Tracking URL = http://yarnmaster:8088/proxy/application_1707982394014_0006/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1707982394014_0006\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-15 09:55:44,574 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-15 09:55:49,656 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 0.93 sec\n",
      "INFO  : 2024-02-15 09:55:54,726 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.04 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 40 msec\n",
      "INFO  : Ended Job = job_1707982394014_0006\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.96 sec   HDFS Read: 72103099 HDFS Write: 465 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.04 sec   HDFS Read: 8081 HDFS Write: 193 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 6 seconds 0 msec\n",
      "INFO  : Completed executing command(queryId=root_20240215095526_416ca2e5-74aa-4176-a789-25d7af248d5b); Time taken: 29.326 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------+------------------+\n",
      "| carrier  | delayed_flights  |\n",
      "+----------+------------------+\n",
      "| WN       | 127601           |\n",
      "| AA       | 59842            |\n",
      "| DL       | 57668            |\n",
      "| UA       | 57367            |\n",
      "| US       | 40943            |\n",
      "+----------+------------------+\n",
      "5 rows selected (29.459 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT carrier, COUNT(*) as delayed_flights FROM flights WHERE arrdelay > 15 GROUP BY carrier \\\n",
    "ORDER BY delayed_flights DESC LIMIT 5;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Con una consulta de HQL muestra: Las 5 compañías que mejor recuperación de tiempo en vuelo tienen.\n",
    "\n",
    "* Se considera que se ha recuperado el tiempo de un vuelo cuando habiendo salido con retraso (`depdelay` > 15), llega sin retraso (`arraydelay` <= 15).\n",
    "* Se trata de que muestres las 5 compañías que han recuperado el tiempo en un mayor porcentaje de vuelos que salieron retrasados.\n",
    "\n",
    "El resultado esperado es el siguiente:\n",
    "\n",
    "![solución 3](./img/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizamos Beeline para conectar con la base de datos Hive 'bda03' . Ejecutamos la consulta que selecciona la compañía aérea y calcula el porcentaje de vuelos recuperados, es decir, los vuelos que tuvieron un retraso en la salida (depdelay) de más de 15 minutos, pero llegaron con un retraso de 15 minutos o menos. Los resultados se ordenan en orden descendente según el porcentaje de vuelos recuperados y se limitan a las 5 primeras compañías aéreas con el mayor porcentaje de vuelos recuperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215095641_c4d6347a-db82-4eea-92a9-4141962ce020): SELECT carrier, COUNT(CASE WHEN arrdelay <= 15 THEN 1 END) / COUNT(*) as percent_recovered  FROM flights WHERE depdelay > 15 GROUP BY carrier ORDER BY percent_recovered DESC LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:carrier, type:string, comment:null), FieldSchema(name:percent_recovered, type:double, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215095641_c4d6347a-db82-4eea-92a9-4141962ce020); Time taken: 0.126 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215095641_c4d6347a-db82-4eea-92a9-4141962ce020): SELECT carrier, COUNT(CASE WHEN arrdelay <= 15 THEN 1 END) / COUNT(*) as percent_recovered  FROM flights WHERE depdelay > 15 GROUP BY carrier ORDER BY percent_recovered DESC LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20240215095641_c4d6347a-db82-4eea-92a9-4141962ce020\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1707982394014_0007\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1707982394014_0007/\n",
      "INFO  : Starting Job = job_1707982394014_0007, Tracking URL = http://yarnmaster:8088/proxy/application_1707982394014_0007/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1707982394014_0007\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-15 09:56:45,026 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-15 09:56:50,105 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.77 sec\n",
      "INFO  : 2024-02-15 09:56:54,161 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.37 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 370 msec\n",
      "INFO  : Ended Job = job_1707982394014_0007\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1707982394014_0008\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1707982394014_0008/\n",
      "INFO  : Starting Job = job_1707982394014_0008, Tracking URL = http://yarnmaster:8088/proxy/application_1707982394014_0008/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1707982394014_0008\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-15 09:56:59,463 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-15 09:57:02,509 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 0.84 sec\n",
      "INFO  : 2024-02-15 09:57:07,576 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 1.95 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 1 seconds 950 msec\n",
      "INFO  : Ended Job = job_1707982394014_0008\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.37 sec   HDFS Read: 72105750 HDFS Write: 544 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 1.95 sec   HDFS Read: 8037 HDFS Write: 261 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 6 seconds 320 msec\n",
      "INFO  : Completed executing command(queryId=root_20240215095641_c4d6347a-db82-4eea-92a9-4141962ce020); Time taken: 26.85 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------+----------------------+\n",
      "| carrier  |  percent_recovered   |\n",
      "+----------+----------------------+\n",
      "| UA       | 0.24507301133462678  |\n",
      "| WN       | 0.23570878543927196  |\n",
      "| FL       | 0.2265728843597696   |\n",
      "| DL       | 0.21578780710414067  |\n",
      "| AA       | 0.20162014676224854  |\n",
      "+----------+----------------------+\n",
      "5 rows selected (27.01 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT carrier, COUNT(CASE WHEN arrdelay <= 15 THEN 1 END) / COUNT(*) as percent_recovered \\\n",
    "FROM flights WHERE depdelay > 15 GROUP BY carrier ORDER BY percent_recovered DESC LIMIT 5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Resuelve el ejercicio 2 con Pig Latin\n",
    "\n",
    "El resultado esperado es:\n",
    "\n",
    "![solución 4](./img/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing delay_flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile delay_flights.pig\n",
    "\n",
    "-- registramos la librería PiggyBank para poder usar la función de carga CSVExcelStorage.\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "-- Leemos el fichero fligths.csv\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (dayofmonth:int, dayofweek:int, carrier:chararray, \n",
    "               depairportid:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "-- Filtramos las llegadas con retraso, seleccionando aquellos vuelos con un retraso en la llegada mayor a 15 minutos.\n",
    "OPERATIONS = filter FLIGHTS by arrdelay > 15;\n",
    "\n",
    "-- Agrupamos los vuelos filtrados por la compañía aérea.\n",
    "\n",
    "TOTAL_OPERATIONS = GROUP OPERATIONS BY carrier;\n",
    "\n",
    "-- Mostramos el esquema resultante.\n",
    "DESCRIBE TOTAL_OPERATIONS;\n",
    "\n",
    "-- Renombramos los campos y se cuenta el número de vuelos retrasados para cada compañía aérea.\n",
    "TOTAL_OPERATIONS = FOREACH TOTAL_OPERATIONS GENERATE group AS carrier, COUNT(OPERATIONS) AS delayed_flights;\n",
    "\n",
    "-- Ordenamos de forma descendente por vuelos\n",
    "TOTAL_OPERATIONS = ORDER TOTAL_OPERATIONS BY delayed_flights DESC;\n",
    "\n",
    "-- Limitamos a 5 aeropuertos\n",
    "TOP5_TOTAL_OPERATIONS = LIMIT TOTAL_OPERATIONS 5;\n",
    "\n",
    "-- Mostramos los resultados.\n",
    "DUMP TOP5_TOTAL_OPERATIONS;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutamos el script \"delay_flights.pig\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:28:32,142 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-02-15 10:28:32,143 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-02-15 10:28:32,169 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-02-15 10:28:32,169 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/TAREA03/notebooks/pig_1707989312168.log\n",
      "2024-02-15 10:28:32,176 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-02-15 10:28:32,247 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-02-15 10:28:32,281 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:28:32,282 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-02-15 10:28:32,294 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-delay_flights.pig-422a5e22-c56e-4fe3-8a34-b2b05646c8c3\n",
      "2024-02-15 10:28:32,294 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "TOTAL_OPERATIONS: {group: chararray,OPERATIONS: {(dayofmonth: int,dayofweek: int,carrier: chararray,depairportid: chararray,arrairportid: chararray,depdelay: int,arrdelay: int)}}\n",
      "2024-02-15 10:28:32,712 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "2024-02-15 10:28:32,738 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-15 10:28:32,769 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:32,793 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2024-02-15 10:28:32,802 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-02-15 10:28:32,810 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-43\n",
      "2024-02-15 10:28:32,814 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 4\n",
      "2024-02-15 10:28:32,814 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 4\n",
      "2024-02-15 10:28:32,881 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsConfig - Loaded properties from hadoop-metrics2.properties\n",
      "2024-02-15 10:28:32,917 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-02-15 10:28:32,917 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started\n",
      "2024-02-15 10:28:32,928 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 10:28:32,930 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:28:32,930 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 10:28:32,931 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2024-02-15 10:28:32,932 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 10:28:32,933 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-15 10:28:32,939 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=72088113\n",
      "2024-02-15 10:28:32,939 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 10:28:32,939 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:28:32,944 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 10:28:32,948 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2024-02-15 10:28:32,948 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2024-02-15 10:28:32,948 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1707989312948-0\n",
      "2024-02-15 10:28:32,987 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 10:28:32,991 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:32,997 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2024-02-15 10:28:33,014 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 10:28:33,023 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:28:33,023 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:28:33,030 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n",
      "2024-02-15 10:28:33,048 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3\n",
      "2024-02-15 10:28:33,102 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local639595835_0001\n",
      "2024-02-15 10:28:33,102 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 10:28:33,167 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 10:28:33,168 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 10:28:33,182 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:28:33,182 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:28:33,182 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:28:33,184 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:33,184 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:33,185 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 10:28:33,205 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 10:28:33,205 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local639595835_0001_m_000000_0\n",
      "2024-02-15 10:28:33,222 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:33,222 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:28:33,229 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:33,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:28:33,239 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/TAREA03/notebooks/flights.csv:0+33554432\n",
      "2024-02-15 10:28:33,258 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:28:33,258 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:28:33,259 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:28:33,259 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:28:33,259 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:28:33,261 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:28:33,274 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:33,275 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2024-02-15 10:28:33,283 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[7,10],FLIGHTS[-1,-1],OPERATIONS[13,13],TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] C: TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] R: TOTAL_OPERATIONS[23,19]\n",
      "2024-02-15 10:28:33,488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local639595835_0001\n",
      "2024-02-15 10:28:33,488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases FLIGHTS,OPERATIONS,TOTAL_OPERATIONS\n",
      "2024-02-15 10:28:33,488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: FLIGHTS[7,10],FLIGHTS[-1,-1],OPERATIONS[13,13],TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] C: TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] R: TOTAL_OPERATIONS[23,19]\n",
      "2024-02-15 10:28:33,489 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2024-02-15 10:28:33,489 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local639595835_0001]\n",
      "2024-02-15 10:28:36,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:28:36,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:28:36,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:28:36,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2747750; bufvoid = 104857600\n",
      "2024-02-15 10:28:36,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25115300(100461200); length = 1099097/6553600\n",
      "2024-02-15 10:28:36,413 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[7,10],FLIGHTS[-1,-1],OPERATIONS[13,13],TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] C: TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] R: TOTAL_OPERATIONS[23,19]\n",
      "2024-02-15 10:28:36,559 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:28:36,565 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local639595835_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:36,566 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:28:36,566 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local639595835_0001_m_000000_0' done.\n",
      "2024-02-15 10:28:36,569 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local639595835_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33559765\n",
      "\t\tFILE: Number of bytes written=629945\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=274775\n",
      "\t\tMap output bytes=2747750\n",
      "\t\tMap output materialized bytes=234\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=274775\n",
      "\t\tCombine output records=16\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=53\n",
      "\t\tTotal committed heap usage (bytes)=729808896\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:28:36,570 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local639595835_0001_m_000000_0\n",
      "2024-02-15 10:28:36,570 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local639595835_0001_m_000001_0\n",
      "2024-02-15 10:28:36,573 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:36,573 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:36,573 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:36,574 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:28:36,576 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/TAREA03/notebooks/flights.csv:33554432+33554432\n",
      "2024-02-15 10:28:36,580 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:28:36,580 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:28:36,580 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:28:36,580 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:28:36,580 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:28:36,581 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:28:36,588 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:36,588 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:36,591 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[7,10],FLIGHTS[-1,-1],OPERATIONS[13,13],TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] C: TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] R: TOTAL_OPERATIONS[23,19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:28:36,990 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 12% complete\n",
      "2024-02-15 10:28:36,990 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local639595835_0001]\n",
      "2024-02-15 10:28:39,610 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:28:39,610 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:28:39,610 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:28:39,610 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2384890; bufvoid = 104857600\n",
      "2024-02-15 10:28:39,610 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25260444(101041776); length = 953953/6553600\n",
      "2024-02-15 10:28:39,700 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:28:39,701 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local639595835_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:39,702 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:28:39,702 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local639595835_0001_m_000001_0' done.\n",
      "2024-02-15 10:28:39,702 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local639595835_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67119454\n",
      "\t\tFILE: Number of bytes written=630209\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=238489\n",
      "\t\tMap output bytes=2384890\n",
      "\t\tMap output materialized bytes=232\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=238489\n",
      "\t\tCombine output records=16\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=78\n",
      "\t\tTotal committed heap usage (bytes)=806879232\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:28:39,702 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local639595835_0001_m_000001_0\n",
      "2024-02-15 10:28:39,702 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local639595835_0001_m_000002_0\n",
      "2024-02-15 10:28:39,704 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:39,704 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:39,705 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:39,706 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:28:39,707 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/TAREA03/notebooks/flights.csv:67108864+4979249\n",
      "2024-02-15 10:28:39,711 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:28:39,711 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:28:39,711 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:28:39,711 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:28:39,711 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:28:39,711 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:28:39,719 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:39,719 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:39,722 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[7,10],FLIGHTS[-1,-1],OPERATIONS[13,13],TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] C: TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] R: TOTAL_OPERATIONS[23,19]\n",
      "2024-02-15 10:28:40,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:28:40,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:28:40,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:28:40,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 247420; bufvoid = 104857600\n",
      "2024-02-15 10:28:40,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26115432(104461728); length = 98965/6553600\n",
      "2024-02-15 10:28:40,201 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:28:40,202 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local639595835_0001_m_000002_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:40,203 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:28:40,203 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local639595835_0001_m_000002_0' done.\n",
      "2024-02-15 10:28:40,203 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local639595835_0001_m_000002_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72099352\n",
      "\t\tFILE: Number of bytes written=630415\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=24742\n",
      "\t\tMap output bytes=247420\n",
      "\t\tMap output materialized bytes=174\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=24742\n",
      "\t\tCombine output records=12\n",
      "\t\tSpilled Records=12\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=27\n",
      "\t\tTotal committed heap usage (bytes)=896008192\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:28:40,203 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local639595835_0001_m_000002_0\n",
      "2024-02-15 10:28:40,203 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 10:28:40,205 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 10:28:40,205 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local639595835_0001_r_000000_0\n",
      "2024-02-15 10:28:40,213 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,213 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,215 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:40,217 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59ab16a3\n",
      "2024-02-15 10:28:40,218 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,226 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 10:28:40,227 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local639595835_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 10:28:40,239 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local639595835_0001_m_000001_0 decomp: 228 len: 232 to MEMORY\n",
      "2024-02-15 10:28:40,241 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 228 bytes from map-output for attempt_local639595835_0001_m_000001_0\n",
      "2024-02-15 10:28:40,241 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 228, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->228\n",
      "2024-02-15 10:28:40,242 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local639595835_0001_m_000002_0 decomp: 170 len: 174 to MEMORY\n",
      "2024-02-15 10:28:40,242 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 170 bytes from map-output for attempt_local639595835_0001_m_000002_0\n",
      "2024-02-15 10:28:40,243 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 170, inMemoryMapOutputs.size() -> 2, commitMemory -> 228, usedMemory ->398\n",
      "2024-02-15 10:28:40,243 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local639595835_0001_m_000000_0 decomp: 230 len: 234 to MEMORY\n",
      "2024-02-15 10:28:40,243 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 230 bytes from map-output for attempt_local639595835_0001_m_000000_0\n",
      "2024-02-15 10:28:40,244 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 230, inMemoryMapOutputs.size() -> 3, commitMemory -> 398, usedMemory ->628\n",
      "2024-02-15 10:28:40,244 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 10:28:40,244 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-15 10:28:40,244 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 10:28:40,247 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 3 sorted segments\n",
      "2024-02-15 10:28:40,247 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 607 bytes\n",
      "2024-02-15 10:28:40,248 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 628 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 10:28:40,248 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 628 bytes from disk\n",
      "2024-02-15 10:28:40,248 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 10:28:40,248 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:28:40,249 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 617 bytes\n",
      "2024-02-15 10:28:40,249 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-15 10:28:40,252 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,252 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,253 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-02-15 10:28:40,253 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:40,253 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:40,254 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[7,10],FLIGHTS[-1,-1],OPERATIONS[13,13],TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] C: TOTAL_OPERATIONS[23,19],TOTAL_OPERATIONS[17,19] R: TOTAL_OPERATIONS[23,19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:28:40,256 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local639595835_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:40,258 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-15 10:28:40,258 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local639595835_0001_r_000000_0 is allowed to commit now\n",
      "2024-02-15 10:28:40,260 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local639595835_0001_r_000000_0' to file:/tmp/temp232622680/tmp-696106867\n",
      "2024-02-15 10:28:40,260 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 10:28:40,260 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local639595835_0001_r_000000_0' done.\n",
      "2024-02-15 10:28:40,261 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local639595835_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72100716\n",
      "\t\tFILE: Number of bytes written=631259\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=16\n",
      "\t\tReduce shuffle bytes=640\n",
      "\t\tReduce input records=44\n",
      "\t\tReduce output records=16\n",
      "\t\tSpilled Records=44\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=896008192\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 10:28:40,261 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local639595835_0001_r_000000_0\n",
      "2024-02-15 10:28:40,261 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-15 10:28:40,414 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 25% complete\n",
      "2024-02-15 10:28:40,415 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,421 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,422 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2024-02-15 10:28:40,422 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,431 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 10:28:40,431 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 10:28:40,432 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 10:28:40,432 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-15 10:28:40,432 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=204\n",
      "2024-02-15 10:28:40,433 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 10:28:40,434 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 10:28:40,444 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 10:28:40,446 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,448 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 10:28:40,451 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:28:40,451 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:28:40,451 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 10:28:40,452 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-15 10:28:40,458 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local635709360_0002\n",
      "2024-02-15 10:28:40,458 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 10:28:40,492 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 10:28:40,493 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 10:28:40,496 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:28:40,496 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:28:40,496 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:28:40,496 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,496 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,496 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 10:28:40,499 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 10:28:40,499 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local635709360_0002_m_000000_0\n",
      "2024-02-15 10:28:40,503 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,503 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,503 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:40,504 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 204\n",
      "Input split[0]:\n",
      "   Length = 204\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:28:40,507 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp232622680/tmp-696106867/part-r-00000:0+204\n",
      "2024-02-15 10:28:40,514 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:28:40,514 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:28:40,514 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:28:40,514 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:28:40,514 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:28:40,516 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:28:40,519 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:40,519 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:40,520 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[26,19] C:  R: \n",
      "2024-02-15 10:28:40,521 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:28:40,521 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:28:40,521 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:28:40,521 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 312; bufvoid = 104857600\n",
      "2024-02-15 10:28:40,521 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-15 10:28:40,522 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:28:40,523 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local635709360_0002_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:40,524 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:28:40,524 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local635709360_0002_m_000000_0' done.\n",
      "2024-02-15 10:28:40,524 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local635709360_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72101368\n",
      "\t\tFILE: Number of bytes written=1244318\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=312\n",
      "\t\tMap output materialized bytes=350\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=2\n",
      "\t\tTotal committed heap usage (bytes)=896532480\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:28:40,524 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local635709360_0002_m_000000_0\n",
      "2024-02-15 10:28:40,524 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 10:28:40,524 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 10:28:40,525 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local635709360_0002_r_000000_0\n",
      "2024-02-15 10:28:40,529 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,529 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,530 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:40,530 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53c7245c\n",
      "2024-02-15 10:28:40,530 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,531 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 10:28:40,531 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local635709360_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 10:28:40,532 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local635709360_0002_m_000000_0 decomp: 346 len: 350 to MEMORY\n",
      "2024-02-15 10:28:40,532 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 346 bytes from map-output for attempt_local635709360_0002_m_000000_0\n",
      "2024-02-15 10:28:40,532 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 346, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->346\n",
      "2024-02-15 10:28:40,533 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 10:28:40,533 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:28:40,533 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 10:28:40,534 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:28:40,534 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 330 bytes\n",
      "2024-02-15 10:28:40,535 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 346 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 10:28:40,535 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 350 bytes from disk\n",
      "2024-02-15 10:28:40,535 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 10:28:40,535 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:28:40,535 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 330 bytes\n",
      "2024-02-15 10:28:40,535 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:28:40,536 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,536 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,537 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:40,537 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:40,539 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[26,19] C:  R: \n",
      "2024-02-15 10:28:40,541 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local635709360_0002_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:40,542 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:28:40,542 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local635709360_0002_r_000000_0 is allowed to commit now\n",
      "2024-02-15 10:28:40,543 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local635709360_0002_r_000000_0' to file:/tmp/temp232622680/tmp287893155\n",
      "2024-02-15 10:28:40,544 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 10:28:40,544 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local635709360_0002_r_000000_0' done.\n",
      "2024-02-15 10:28:40,544 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local635709360_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102100\n",
      "\t\tFILE: Number of bytes written=1244731\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=350\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=16\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=896532480\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 10:28:40,544 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local635709360_0002_r_000000_0\n",
      "2024-02-15 10:28:40,544 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:28:40,693 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local635709360_0002\n",
      "2024-02-15 10:28:40,693 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases TOTAL_OPERATIONS\n",
      "2024-02-15 10:28:40,693 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: TOTAL_OPERATIONS[26,19] C:  R: \n",
      "2024-02-15 10:28:40,693 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n",
      "2024-02-15 10:28:40,694 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,695 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,696 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,698 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 10:28:40,698 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 10:28:40,699 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 10:28:40,699 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 10:28:40,699 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 10:28:40,709 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 10:28:40,710 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,712 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 10:28:40,714 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:28:40,714 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:28:40,714 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 10:28:40,715 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-15 10:28:40,724 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1047169466_0003\n",
      "2024-02-15 10:28:40,724 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 10:28:40,757 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 10:28:40,757 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 10:28:40,760 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:28:40,760 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:28:40,760 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:28:40,760 [Thread-24] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,760 [Thread-24] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,761 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 10:28:40,763 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 10:28:40,763 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1047169466_0003_m_000000_0\n",
      "2024-02-15 10:28:40,767 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,767 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,767 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:40,768 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 204\n",
      "Input split[0]:\n",
      "   Length = 204\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:28:40,769 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp232622680/tmp-696106867/part-r-00000:0+204\n",
      "2024-02-15 10:28:40,773 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:28:40,773 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:28:40,773 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:28:40,773 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:28:40,773 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:28:40,774 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:28:40,774 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:40,774 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:40,775 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[26,19] C:  R: \n",
      "2024-02-15 10:28:40,776 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:28:40,776 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:28:40,776 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:28:40,776 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288; bufvoid = 104857600\n",
      "2024-02-15 10:28:40,776 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-15 10:28:40,780 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:28:40,781 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1047169466_0003_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:40,781 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:28:40,781 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1047169466_0003_m_000000_0' done.\n",
      "2024-02-15 10:28:40,782 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1047169466_0003_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102752\n",
      "\t\tFILE: Number of bytes written=1866331\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=288\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=16\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=896532480\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:28:40,782 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1047169466_0003_m_000000_0\n",
      "2024-02-15 10:28:40,782 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 10:28:40,782 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 10:28:40,782 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1047169466_0003_r_000000_0\n",
      "2024-02-15 10:28:40,786 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,786 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,787 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:40,787 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@280feb82\n",
      "2024-02-15 10:28:40,787 [pool-12-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,788 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 10:28:40,788 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1047169466_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 10:28:40,789 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1047169466_0003_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-02-15 10:28:40,789 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local1047169466_0003_m_000000_0\n",
      "2024-02-15 10:28:40,789 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-02-15 10:28:40,789 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 10:28:40,790 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:28:40,790 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 10:28:40,790 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:28:40,791 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-15 10:28:40,791 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 10:28:40,791 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-02-15 10:28:40,791 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 10:28:40,791 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:28:40,791 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-15 10:28:40,791 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:28:40,792 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:40,792 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:40,793 [pool-12-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:40,793 [pool-12-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:40,794 [pool-12-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[26,19] C:  R: \n",
      "2024-02-15 10:28:40,794 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1047169466_0003_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:40,795 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:28:40,795 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1047169466_0003_r_000000_0 is allowed to commit now\n",
      "2024-02-15 10:28:40,796 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1047169466_0003_r_000000_0' to file:/tmp/temp232622680/tmp-1587914520\n",
      "2024-02-15 10:28:40,797 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 10:28:40,797 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1047169466_0003_r_000000_0' done.\n",
      "2024-02-15 10:28:40,797 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1047169466_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102996\n",
      "\t\tFILE: Number of bytes written=1866519\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=896532480\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 10:28:40,797 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1047169466_0003_r_000000_0\n",
      "2024-02-15 10:28:40,797 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:28:40,957 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1047169466_0003\n",
      "2024-02-15 10:28:40,957 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases TOTAL_OPERATIONS\n",
      "2024-02-15 10:28:40,957 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: TOTAL_OPERATIONS[26,19] C:  R: \n",
      "2024-02-15 10:28:40,958 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 75% complete\n",
      "2024-02-15 10:28:40,959 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,960 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,960 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,962 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 10:28:40,962 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 10:28:40,962 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 10:28:40,962 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 10:28:40,963 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 10:28:40,969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 10:28:40,970 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:40,972 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 10:28:40,973 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:28:40,973 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:28:40,973 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 10:28:40,974 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-15 10:28:40,978 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1434056528_0004\n",
      "2024-02-15 10:28:40,978 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 10:28:41,012 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 10:28:41,013 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 10:28:41,016 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:28:41,016 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:28:41,016 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:28:41,016 [Thread-31] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:41,016 [Thread-31] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:41,016 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 10:28:41,018 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 10:28:41,018 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1434056528_0004_m_000000_0\n",
      "2024-02-15 10:28:41,022 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:41,022 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:41,022 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:41,023 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 70\n",
      "Input split[0]:\n",
      "   Length = 70\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:28:41,024 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp232622680/tmp-1587914520/part-r-00000:0+70\n",
      "2024-02-15 10:28:41,028 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:28:41,028 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:28:41,028 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:28:41,028 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:28:41,028 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:28:41,028 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:28:41,029 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:41,029 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:41,029 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[26,19] C:  R: \n",
      "2024-02-15 10:28:41,029 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:28:41,029 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:28:41,030 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:28:41,030 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 90; bufvoid = 104857600\n",
      "2024-02-15 10:28:41,030 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2024-02-15 10:28:41,030 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:28:41,031 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1434056528_0004_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:41,032 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:28:41,032 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1434056528_0004_m_000000_0' done.\n",
      "2024-02-15 10:28:41,032 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1434056528_0004_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103514\n",
      "\t\tFILE: Number of bytes written=2475636\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=90\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=897056768\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:28:41,032 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1434056528_0004_m_000000_0\n",
      "2024-02-15 10:28:41,032 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 10:28:41,032 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 10:28:41,032 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1434056528_0004_r_000000_0\n",
      "2024-02-15 10:28:41,036 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:41,036 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:41,036 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:28:41,036 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@255a7cd9\n",
      "2024-02-15 10:28:41,036 [pool-15-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,037 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 10:28:41,037 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1434056528_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 10:28:41,038 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local1434056528_0004_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-02-15 10:28:41,038 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local1434056528_0004_m_000000_0\n",
      "2024-02-15 10:28:41,038 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-02-15 10:28:41,039 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 10:28:41,039 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:28:41,039 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 10:28:41,039 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:28:41,039 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-15 10:28:41,040 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 10:28:41,040 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-02-15 10:28:41,040 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 10:28:41,040 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:28:41,040 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-15 10:28:41,040 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:28:41,041 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:28:41,041 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:28:41,042 [pool-15-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:28:41,042 [pool-15-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:41,042 [pool-15-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[26,19] C:  R: \n",
      "2024-02-15 10:28:41,043 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1434056528_0004_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:28:41,044 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:28:41,044 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1434056528_0004_r_000000_0 is allowed to commit now\n",
      "2024-02-15 10:28:41,045 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1434056528_0004_r_000000_0' to file:/tmp/temp232622680/tmp991815138\n",
      "2024-02-15 10:28:41,045 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 10:28:41,045 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1434056528_0004_r_000000_0' done.\n",
      "2024-02-15 10:28:41,045 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1434056528_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103758\n",
      "\t\tFILE: Number of bytes written=2475824\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=897056768\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 10:28:41,045 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1434056528_0004_r_000000_0\n",
      "2024-02-15 10:28:41,045 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:28:41,213 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1434056528_0004\n",
      "2024-02-15 10:28:41,213 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases TOTAL_OPERATIONS\n",
      "2024-02-15 10:28:41,213 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: TOTAL_OPERATIONS[26,19] C:  R: \n",
      "2024-02-15 10:28:41,214 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,215 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,215 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,218 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2024-02-15 10:28:41,221 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.3.1\t0.17.0\troot\t2024-02-15 10:28:32\t2024-02-15 10:28:41\tGROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local1047169466_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tTOTAL_OPERATIONS\tORDER_BY,COMBINER\t\n",
      "job_local1434056528_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tTOTAL_OPERATIONS\t\tfile:/tmp/temp232622680/tmp991815138,\n",
      "job_local635709360_0002\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tTOTAL_OPERATIONS\tSAMPLER\t\n",
      "job_local639595835_0001\t3\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tFLIGHTS,OPERATIONS,TOTAL_OPERATIONS\tGROUP_BY,COMBINER\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/TAREA03/notebooks/flights.csv\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 5 records in: \"file:/tmp/temp232622680/tmp991815138\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 5\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local639595835_0001\t->\tjob_local635709360_0002,\n",
      "job_local635709360_0002\t->\tjob_local1047169466_0003,\n",
      "job_local1047169466_0003\t->\tjob_local1434056528_0004,\n",
      "job_local1434056528_0004\n",
      "\n",
      "\n",
      "2024-02-15 10:28:41,221 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,222 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,222 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,226 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,226 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,227 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,228 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,229 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,229 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,231 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,231 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,232 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:28:41,233 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2024-02-15 10:28:41,234 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:28:41,235 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:28:41,235 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(WN,127601)\n",
      "(AA,59842)\n",
      "(DL,57668)\n",
      "(UA,57367)\n",
      "(US,40943)\n",
      "2024-02-15 10:28:41,263 [main] INFO  org.apache.pig.Main - Pig script completed in 9 seconds and 195 milliseconds (9195 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f delay_flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/delayed_flights'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Resuelve el ejercicio 3 con Pig Latin\n",
    "\n",
    "Se espera el siguiente resultado:\n",
    "\n",
    "![solución 5](./img/5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing recovery.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile recovery.pig\n",
    "\n",
    "-- Leemos el archivo flights.csv.\n",
    "flights_data = LOAD '$flights_file' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (dayofmonth:int, dayofweek:int, carrier:chararray, \n",
    "              depairportid:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "-- Filtramos de vuelos con salida retrasada y vuelos recuperados.\n",
    "delayed_flights = FILTER flights_data BY depdelay > 15;\n",
    "recovered_flights = FILTER flights_data BY depdelay > 15 AND arrdelay <= 15;\n",
    "\n",
    "-- Agrupamos los vuelos con salida retrasada por compañía aérea.\n",
    "grouped_delayed_flights = GROUP delayed_flights BY carrier;\n",
    "delayed_count = FOREACH grouped_delayed_flights GENERATE\n",
    "    group AS carrier,\n",
    "    COUNT(delayed_flights) AS delayed_count;\n",
    "\n",
    "-- Agrupamos los vuelos recuperados por compañía aérea.\n",
    "grouped_recovered_flights = GROUP recovered_flights BY carrier;\n",
    "recovered_count = FOREACH grouped_recovered_flights GENERATE\n",
    "    group AS carrier,\n",
    "    COUNT(recovered_flights) AS recovered_count;\n",
    "\n",
    "-- Mostramos el esquema de las relaciones resultantes.\n",
    "DESCRIBE grouped_delayed_flights;\n",
    "DESCRIBE grouped_recovered_flights;\n",
    "\n",
    "-- Unimos los conteos de vuelos con salida retrasada y vuelos recuperados.\n",
    "joined_counts = JOIN delayed_count BY carrier, recovered_count BY carrier;\n",
    "\n",
    "-- Cálculamos el porcentaje de vuelos recuperados.\n",
    "percent_recovered = FOREACH joined_counts GENERATE\n",
    "    delayed_count::carrier AS carrier,\n",
    "    recovered_count / (float)delayed_count::delayed_count AS percent_recovered;\n",
    "\n",
    "-- Ordenamos descendente por el porcentaje de vuelos recuperados.\n",
    "ordered_flights = ORDER percent_recovered BY percent_recovered DESC;\n",
    "\n",
    "-- Limitamos de resultados a los 5 primeros.\n",
    "limited_flights = LIMIT ordered_flights 5;\n",
    "\n",
    "-- Mostramos de los resultados finales.\n",
    "DUMP limited_flights;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutamos el script recovery.pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:30:32,788 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-02-15 10:30:32,788 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-02-15 10:30:32,814 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-02-15 10:30:32,814 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/TAREA03/notebooks/pig_1707989432813.log\n",
      "2024-02-15 10:30:32,822 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-02-15 10:30:32,893 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-02-15 10:30:32,928 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:30:32,928 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-02-15 10:30:32,940 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-recovery.pig-74f330e7-7d09-4b2f-8384-983661aaaec3\n",
      "2024-02-15 10:30:32,940 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "grouped_delayed_flights: {group: chararray,delayed_flights: {(dayofmonth: int,dayofweek: int,carrier: chararray,depairportid: chararray,arrairportid: chararray,depdelay: int,arrdelay: int)}}\n",
      "grouped_recovered_flights: {group: chararray,recovered_flights: {(dayofmonth: int,dayofweek: int,carrier: chararray,depairportid: chararray,arrairportid: chararray,depdelay: int,arrdelay: int)}}\n",
      "2024-02-15 10:30:33,397 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan - Encountered Warning IMPLICIT_CAST_TO_FLOAT 1 time(s).\n",
      "2024-02-15 10:30:33,401 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "2024-02-15 10:30:33,426 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-15 10:30:33,458 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:33,484 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2024-02-15 10:30:33,493 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-02-15 10:30:33,496 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-02-15 10:30:33,501 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-100\n",
      "2024-02-15 10:30:33,503 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer - Rewrite: POPackage->POForEach to POPackage(JoinPackager)\n",
      "2024-02-15 10:30:33,506 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 7\n",
      "2024-02-15 10:30:33,507 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged MR job 87 into MR job 84\n",
      "2024-02-15 10:30:33,507 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged MR job 92 into MR job 84\n",
      "2024-02-15 10:30:33,507 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Requested parallelism of splitter: -1\n",
      "2024-02-15 10:30:33,507 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 2 map-reduce splittees.\n",
      "2024-02-15 10:30:33,507 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 2 out of total 3 MR operators.\n",
      "2024-02-15 10:30:33,507 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 5\n",
      "2024-02-15 10:30:33,573 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsConfig - Loaded properties from hadoop-metrics2.properties\n",
      "2024-02-15 10:30:33,609 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-02-15 10:30:33,609 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started\n",
      "2024-02-15 10:30:33,620 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 10:30:33,623 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:30:33,623 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 10:30:33,624 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2024-02-15 10:30:33,625 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 10:30:33,625 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-15 10:30:33,630 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=72088113\n",
      "2024-02-15 10:30:33,631 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 10:30:33,631 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:30:33,636 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up multi store job\n",
      "2024-02-15 10:30:33,640 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2024-02-15 10:30:33,640 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2024-02-15 10:30:33,640 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1707989433640-0\n",
      "2024-02-15 10:30:33,684 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 10:30:33,687 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:33,693 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2024-02-15 10:30:33,712 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 10:30:33,722 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:30:33,722 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:30:33,730 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n",
      "2024-02-15 10:30:33,745 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:30:33,802 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1659756285_0001\n",
      "2024-02-15 10:30:33,802 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 10:30:33,862 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 10:30:33,862 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 10:30:33,876 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:30:33,876 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:30:33,876 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:30:33,878 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:33,878 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:33,880 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:33,880 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:33,880 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 10:30:33,903 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 10:30:33,903 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1659756285_0001_m_000000_0\n",
      "2024-02-15 10:30:33,923 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:33,923 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:33,924 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:33,924 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:33,932 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:33,936 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:30:33,942 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/TAREA03/notebooks/flights.csv:0+33554432\n",
      "2024-02-15 10:30:33,960 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:30:33,960 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:30:33,960 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:30:33,960 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:30:33,960 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:30:33,962 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:30:33,975 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:33,976 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2024-02-15 10:30:33,984 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: flights_data[3,15],flights_data[-1,-1],delayed_flights[8,18],delayed_count[13,16],grouped_delayed_flights[12,26],recovered_flights[9,20],recovered_count[19,18],grouped_recovered_flights[18,28] C: delayed_count[13,16],grouped_delayed_flights[12,26],recovered_count[19,18],grouped_recovered_flights[18,28] R: delayed_count[13,16],recovered_count[19,18]\n",
      "2024-02-15 10:30:34,185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1659756285_0001\n",
      "2024-02-15 10:30:34,185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases delayed_count,delayed_flights,flights_data,grouped_delayed_flights,grouped_recovered_flights,recovered_count,recovered_flights\n",
      "2024-02-15 10:30:34,185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: flights_data[3,15],flights_data[-1,-1],delayed_flights[8,18],delayed_count[13,16],grouped_delayed_flights[12,26],recovered_flights[9,20],recovered_count[19,18],grouped_recovered_flights[18,28] C: delayed_count[13,16],grouped_delayed_flights[12,26],recovered_count[19,18],grouped_recovered_flights[18,28] R: delayed_count[13,16],recovered_count[19,18]\n",
      "2024-02-15 10:30:34,186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2024-02-15 10:30:34,186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1659756285_0001]\n",
      "2024-02-15 10:30:37,473 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:30:37,473 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:30:37,473 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:30:37,473 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 3119320; bufvoid = 104857600\n",
      "2024-02-15 10:30:37,473 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24966672(99866688); length = 1247725/6553600\n",
      "2024-02-15 10:30:37,538 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: flights_data[3,15],flights_data[-1,-1],delayed_flights[8,18],delayed_count[13,16],grouped_delayed_flights[12,26],recovered_flights[9,20],recovered_count[19,18],grouped_recovered_flights[18,28] C: delayed_count[13,16],grouped_delayed_flights[12,26],recovered_count[19,18],grouped_recovered_flights[18,28] R: delayed_count[13,16],recovered_count[19,18]\n",
      "2024-02-15 10:30:37,656 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:30:37,661 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1659756285_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:37,662 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:30:37,662 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1659756285_0001_m_000000_0' done.\n",
      "2024-02-15 10:30:37,665 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1659756285_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33559765\n",
      "\t\tFILE: Number of bytes written=642556\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=311932\n",
      "\t\tMap output bytes=3119320\n",
      "\t\tMap output materialized bytes=455\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=311932\n",
      "\t\tCombine output records=32\n",
      "\t\tSpilled Records=32\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=26\n",
      "\t\tTotal committed heap usage (bytes)=524812288\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:30:37,665 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1659756285_0001_m_000000_0\n",
      "2024-02-15 10:30:37,666 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1659756285_0001_m_000001_0\n",
      "2024-02-15 10:30:37,668 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:37,668 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:37,669 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:37,669 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:37,669 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:37,670 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:30:37,672 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/TAREA03/notebooks/flights.csv:33554432+33554432\n",
      "2024-02-15 10:30:37,676 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:30:37,676 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:30:37,676 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:30:37,676 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:30:37,676 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:30:37,676 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:30:37,683 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:37,683 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:37,686 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: flights_data[3,15],flights_data[-1,-1],delayed_flights[8,18],delayed_count[13,16],grouped_delayed_flights[12,26],recovered_flights[9,20],recovered_count[19,18],grouped_recovered_flights[18,28] C: delayed_count[13,16],grouped_delayed_flights[12,26],recovered_count[19,18],grouped_recovered_flights[18,28] R: delayed_count[13,16],recovered_count[19,18]\n",
      "2024-02-15 10:30:37,687 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 10% complete\n",
      "2024-02-15 10:30:37,688 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1659756285_0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:30:41,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:30:41,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:30:41,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:30:41,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2854600; bufvoid = 104857600\n",
      "2024-02-15 10:30:41,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25072560(100290240); length = 1141837/6553600\n",
      "2024-02-15 10:30:41,239 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:30:41,240 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1659756285_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:41,241 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:30:41,241 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1659756285_0001_m_000001_0' done.\n",
      "2024-02-15 10:30:41,241 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1659756285_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67119454\n",
      "\t\tFILE: Number of bytes written=643043\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=285460\n",
      "\t\tMap output bytes=2854600\n",
      "\t\tMap output materialized bytes=455\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=285460\n",
      "\t\tCombine output records=32\n",
      "\t\tSpilled Records=32\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=58\n",
      "\t\tTotal committed heap usage (bytes)=670564352\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:30:41,241 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1659756285_0001_m_000001_0\n",
      "2024-02-15 10:30:41,241 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1659756285_0001_m_000002_0\n",
      "2024-02-15 10:30:41,244 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:41,244 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:41,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:41,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:41,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:41,246 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:30:41,248 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/TAREA03/notebooks/flights.csv:67108864+4979249\n",
      "2024-02-15 10:30:41,252 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:30:41,252 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:30:41,252 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:30:41,252 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:30:41,252 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:30:41,252 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:30:41,260 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:41,260 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:41,263 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: flights_data[3,15],flights_data[-1,-1],delayed_flights[8,18],delayed_count[13,16],grouped_delayed_flights[12,26],recovered_flights[9,20],recovered_count[19,18],grouped_recovered_flights[18,28] C: delayed_count[13,16],grouped_delayed_flights[12,26],recovered_count[19,18],grouped_recovered_flights[18,28] R: delayed_count[13,16],recovered_count[19,18]\n",
      "2024-02-15 10:30:41,821 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:30:41,821 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:30:41,821 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:30:41,821 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288340; bufvoid = 104857600\n",
      "2024-02-15 10:30:41,821 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26099064(104396256); length = 115333/6553600\n",
      "2024-02-15 10:30:41,836 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:30:41,837 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1659756285_0001_m_000002_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:41,838 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:30:41,838 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1659756285_0001_m_000002_0' done.\n",
      "2024-02-15 10:30:41,838 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1659756285_0001_m_000002_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72099352\n",
      "\t\tFILE: Number of bytes written=643414\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=28834\n",
      "\t\tMap output bytes=288340\n",
      "\t\tMap output materialized bytes=339\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=28834\n",
      "\t\tCombine output records=24\n",
      "\t\tSpilled Records=24\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=73\n",
      "\t\tTotal committed heap usage (bytes)=745537536\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:30:41,838 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1659756285_0001_m_000002_0\n",
      "2024-02-15 10:30:41,838 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 10:30:41,840 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 10:30:41,840 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1659756285_0001_r_000000_0\n",
      "2024-02-15 10:30:41,847 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:41,847 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:41,848 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:41,848 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:30:41,850 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:41,851 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@726de6d7\n",
      "2024-02-15 10:30:41,852 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:41,861 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 10:30:41,862 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1659756285_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 10:30:41,875 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1659756285_0001_m_000001_0 decomp: 451 len: 455 to MEMORY\n",
      "2024-02-15 10:30:41,876 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 451 bytes from map-output for attempt_local1659756285_0001_m_000001_0\n",
      "2024-02-15 10:30:41,877 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->451\n",
      "2024-02-15 10:30:41,878 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1659756285_0001_m_000000_0 decomp: 451 len: 455 to MEMORY\n",
      "2024-02-15 10:30:41,878 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 451 bytes from map-output for attempt_local1659756285_0001_m_000000_0\n",
      "2024-02-15 10:30:41,878 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 451, inMemoryMapOutputs.size() -> 2, commitMemory -> 451, usedMemory ->902\n",
      "2024-02-15 10:30:41,879 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1659756285_0001_m_000002_0 decomp: 335 len: 339 to MEMORY\n",
      "2024-02-15 10:30:41,879 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 335 bytes from map-output for attempt_local1659756285_0001_m_000002_0\n",
      "2024-02-15 10:30:41,879 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 335, inMemoryMapOutputs.size() -> 3, commitMemory -> 902, usedMemory ->1237\n",
      "2024-02-15 10:30:41,880 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 10:30:41,880 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-15 10:30:41,880 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 10:30:41,883 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 3 sorted segments\n",
      "2024-02-15 10:30:41,883 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 1216 bytes\n",
      "2024-02-15 10:30:41,884 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 1237 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 10:30:41,884 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1237 bytes from disk\n",
      "2024-02-15 10:30:41,884 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 10:30:41,884 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:30:41,884 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1226 bytes\n",
      "2024-02-15 10:30:41,885 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-15 10:30:41,886 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-02-15 10:30:41,886 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:41,886 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:41,888 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: flights_data[3,15],flights_data[-1,-1],delayed_flights[8,18],delayed_count[13,16],grouped_delayed_flights[12,26],recovered_flights[9,20],recovered_count[19,18],grouped_recovered_flights[18,28] C: delayed_count[13,16],grouped_delayed_flights[12,26],recovered_count[19,18],grouped_recovered_flights[18,28] R: delayed_count[13,16],recovered_count[19,18]\n",
      "2024-02-15 10:30:41,890 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:41,890 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:41,892 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:41,892 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:41,895 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1659756285_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:41,897 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-15 10:30:41,897 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1659756285_0001_r_000000_0 is allowed to commit now\n",
      "2024-02-15 10:30:41,899 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1659756285_0001_r_000000_0' to file:/tmp/temp1453782073/tmp-1355324359\n",
      "2024-02-15 10:30:41,900 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1659756285_0001_r_000000_0' to file:/tmp/temp1453782073/tmp-1262683736\n",
      "2024-02-15 10:30:41,901 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 10:30:41,901 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1659756285_0001_r_000000_0' done.\n",
      "2024-02-15 10:30:41,901 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1659756285_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72101934\n",
      "\t\tFILE: Number of bytes written=645071\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=32\n",
      "\t\tReduce shuffle bytes=1249\n",
      "\t\tReduce input records=88\n",
      "\t\tReduce output records=0\n",
      "\t\tSpilled Records=88\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=745537536\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 10:30:41,901 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1659756285_0001_r_000000_0\n",
      "2024-02-15 10:30:41,901 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:30:42,097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 20% complete\n",
      "2024-02-15 10:30:42,099 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,105 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,106 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2024-02-15 10:30:42,106 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,121 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 10:30:42,121 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 10:30:42,122 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 10:30:42,122 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-15 10:30:42,123 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=396\n",
      "2024-02-15 10:30:42,123 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 10:30:42,124 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 10:30:42,133 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 10:30:42,134 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,137 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 10:30:42,140 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:30:42,140 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:30:42,140 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 10:30:42,141 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:30:42,141 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:30:42,141 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 10:30:42,142 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2024-02-15 10:30:42,148 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1254809559_0002\n",
      "2024-02-15 10:30:42,148 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 10:30:42,184 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 10:30:42,185 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 10:30:42,188 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:30:42,188 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:30:42,188 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:30:42,188 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,188 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,188 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 10:30:42,191 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 10:30:42,191 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1254809559_0002_m_000000_0\n",
      "2024-02-15 10:30:42,195 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,195 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,195 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:42,196 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 202\n",
      "Input split[0]:\n",
      "   Length = 202\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:30:42,198 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1453782073/tmp-1355324359/part-r-00000:0+202\n",
      "2024-02-15 10:30:42,202 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:30:42,202 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:30:42,202 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:30:42,202 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,202 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:30:42,203 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:30:42,206 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:42,206 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:42,207 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: joined_counts[28,16],joined_counts[28,16] C:  R: percent_recovered[31,20]\n",
      "2024-02-15 10:30:42,208 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:30:42,208 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:30:42,208 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:30:42,208 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 186; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,208 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-15 10:30:42,209 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:30:42,210 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1254809559_0002_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:42,211 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:30:42,211 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1254809559_0002_m_000000_0' done.\n",
      "2024-02-15 10:30:42,211 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1254809559_0002_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102985\n",
      "\t\tFILE: Number of bytes written=1259301\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=186\n",
      "\t\tMap output materialized bytes=224\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=745537536\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _0_tmp-1355324359=16\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:30:42,211 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1254809559_0002_m_000000_0\n",
      "2024-02-15 10:30:42,211 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1254809559_0002_m_000001_0\n",
      "2024-02-15 10:30:42,213 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,213 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,213 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:42,214 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 194\n",
      "Input split[0]:\n",
      "   Length = 194\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:30:42,215 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1453782073/tmp-1262683736/part-r-00000:0+194\n",
      "2024-02-15 10:30:42,228 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:30:42,228 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:30:42,229 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:30:42,229 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,229 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:30:42,229 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:30:42,231 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:42,231 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:42,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: joined_counts[28,16],joined_counts[28,16] C:  R: percent_recovered[31,20]\n",
      "2024-02-15 10:30:42,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:30:42,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:30:42,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:30:42,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 178; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-15 10:30:42,233 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:30:42,233 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1254809559_0002_m_000001_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:42,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:30:42,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1254809559_0002_m_000001_0' done.\n",
      "2024-02-15 10:30:42,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1254809559_0002_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103976\n",
      "\t\tFILE: Number of bytes written=1259549\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=178\n",
      "\t\tMap output materialized bytes=216\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=9\n",
      "\t\tTotal committed heap usage (bytes)=746061824\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _1_tmp-1262683736=16\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:30:42,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1254809559_0002_m_000001_0\n",
      "2024-02-15 10:30:42,234 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 10:30:42,235 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 10:30:42,235 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1254809559_0002_r_000000_0\n",
      "2024-02-15 10:30:42,239 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,239 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,240 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:42,240 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@536025bf\n",
      "2024-02-15 10:30:42,240 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,240 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 10:30:42,241 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1254809559_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 10:30:42,242 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1254809559_0002_m_000000_0 decomp: 220 len: 224 to MEMORY\n",
      "2024-02-15 10:30:42,242 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 220 bytes from map-output for attempt_local1254809559_0002_m_000000_0\n",
      "2024-02-15 10:30:42,242 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220\n",
      "2024-02-15 10:30:42,243 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1254809559_0002_m_000001_0 decomp: 212 len: 216 to MEMORY\n",
      "2024-02-15 10:30:42,243 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 212 bytes from map-output for attempt_local1254809559_0002_m_000001_0\n",
      "2024-02-15 10:30:42,243 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 212, inMemoryMapOutputs.size() -> 2, commitMemory -> 220, usedMemory ->432\n",
      "2024-02-15 10:30:42,243 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 10:30:42,243 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-02-15 10:30:42,243 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 10:30:42,244 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 2 sorted segments\n",
      "2024-02-15 10:30:42,244 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 418 bytes\n",
      "2024-02-15 10:30:42,245 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 432 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 10:30:42,245 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 434 bytes from disk\n",
      "2024-02-15 10:30:42,245 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 10:30:42,245 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:30:42,245 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 423 bytes\n",
      "2024-02-15 10:30:42,245 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-02-15 10:30:42,247 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,247 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,248 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:42,248 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:42,249 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: joined_counts[28,16],joined_counts[28,16] C:  R: percent_recovered[31,20]\n",
      "2024-02-15 10:30:42,253 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1254809559_0002_r_000000_0 is done. And is in the process of committing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:30:42,254 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-02-15 10:30:42,254 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1254809559_0002_r_000000_0 is allowed to commit now\n",
      "2024-02-15 10:30:42,255 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1254809559_0002_r_000000_0' to file:/tmp/temp1453782073/tmp-1569116790\n",
      "2024-02-15 10:30:42,256 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 10:30:42,256 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1254809559_0002_r_000000_0' done.\n",
      "2024-02-15 10:30:42,256 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1254809559_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72104914\n",
      "\t\tFILE: Number of bytes written=1260219\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=16\n",
      "\t\tReduce shuffle bytes=440\n",
      "\t\tReduce input records=32\n",
      "\t\tReduce output records=16\n",
      "\t\tSpilled Records=32\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=746061824\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 10:30:42,256 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1254809559_0002_r_000000_0\n",
      "2024-02-15 10:30:42,256 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-15 10:30:42,385 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1254809559_0002\n",
      "2024-02-15 10:30:42,385 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases joined_counts,percent_recovered\n",
      "2024-02-15 10:30:42,385 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: joined_counts[28,16],joined_counts[28,16] C:  R: percent_recovered[31,20]\n",
      "2024-02-15 10:30:42,386 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 40% complete\n",
      "2024-02-15 10:30:42,386 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,387 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,388 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,391 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 10:30:42,391 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 10:30:42,392 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 10:30:42,392 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-15 10:30:42,392 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=224\n",
      "2024-02-15 10:30:42,393 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 10:30:42,393 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 10:30:42,403 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 10:30:42,404 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,406 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 10:30:42,407 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:30:42,407 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:30:42,407 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 10:30:42,408 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-15 10:30:42,417 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1079352555_0003\n",
      "2024-02-15 10:30:42,417 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 10:30:42,450 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 10:30:42,450 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 10:30:42,453 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:30:42,453 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:30:42,453 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:30:42,454 [Thread-25] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,454 [Thread-25] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,454 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 10:30:42,456 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 10:30:42,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1079352555_0003_m_000000_0\n",
      "2024-02-15 10:30:42,460 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,460 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,460 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:42,460 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 224\n",
      "Input split[0]:\n",
      "   Length = 224\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:30:42,461 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1453782073/tmp-1569116790/part-r-00000:0+224\n",
      "2024-02-15 10:30:42,465 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:30:42,465 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:30:42,465 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:30:42,465 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,465 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:30:42,467 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:30:42,468 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:42,468 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:42,469 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: ordered_flights[36,18] C:  R: \n",
      "2024-02-15 10:30:42,471 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:30:42,471 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:30:42,471 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:30:42,471 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 352; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,471 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-15 10:30:42,472 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:30:42,473 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1079352555_0003_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:42,474 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:30:42,474 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1079352555_0003_m_000000_0' done.\n",
      "2024-02-15 10:30:42,474 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1079352555_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72105588\n",
      "\t\tFILE: Number of bytes written=1876236\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=352\n",
      "\t\tMap output materialized bytes=390\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=746061824\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:30:42,474 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1079352555_0003_m_000000_0\n",
      "2024-02-15 10:30:42,474 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 10:30:42,474 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 10:30:42,474 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1079352555_0003_r_000000_0\n",
      "2024-02-15 10:30:42,478 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,478 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,479 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:42,479 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20d74647\n",
      "2024-02-15 10:30:42,479 [pool-12-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,480 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 10:30:42,480 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1079352555_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 10:30:42,481 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1079352555_0003_m_000000_0 decomp: 386 len: 390 to MEMORY\n",
      "2024-02-15 10:30:42,481 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 386 bytes from map-output for attempt_local1079352555_0003_m_000000_0\n",
      "2024-02-15 10:30:42,481 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 386, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->386\n",
      "2024-02-15 10:30:42,481 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 10:30:42,481 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:30:42,481 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 10:30:42,482 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:30:42,482 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 370 bytes\n",
      "2024-02-15 10:30:42,482 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 386 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 10:30:42,482 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 390 bytes from disk\n",
      "2024-02-15 10:30:42,482 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 10:30:42,483 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:30:42,483 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 370 bytes\n",
      "2024-02-15 10:30:42,483 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:30:42,484 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,484 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,484 [pool-12-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:42,484 [pool-12-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:42,486 [pool-12-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: ordered_flights[36,18] C:  R: \n",
      "2024-02-15 10:30:42,487 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1079352555_0003_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:42,488 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:30:42,488 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1079352555_0003_r_000000_0 is allowed to commit now\n",
      "2024-02-15 10:30:42,489 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1079352555_0003_r_000000_0' to file:/tmp/temp1453782073/tmp-933357412\n",
      "2024-02-15 10:30:42,489 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 10:30:42,489 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1079352555_0003_r_000000_0' done.\n",
      "2024-02-15 10:30:42,489 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1079352555_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72106400\n",
      "\t\tFILE: Number of bytes written=1876691\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=390\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=16\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=746061824\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 10:30:42,489 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1079352555_0003_r_000000_0\n",
      "2024-02-15 10:30:42,489 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:30:42,650 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1079352555_0003\n",
      "2024-02-15 10:30:42,651 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases ordered_flights\n",
      "2024-02-15 10:30:42,651 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: ordered_flights[36,18] C:  R: \n",
      "2024-02-15 10:30:42,651 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 60% complete\n",
      "2024-02-15 10:30:42,652 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,653 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,653 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,655 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 10:30:42,655 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 10:30:42,656 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 10:30:42,656 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 10:30:42,656 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 10:30:42,666 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 10:30:42,667 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,669 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 10:30:42,670 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:30:42,670 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:30:42,670 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 10:30:42,671 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-15 10:30:42,675 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local764858715_0004\n",
      "2024-02-15 10:30:42,675 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 10:30:42,710 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 10:30:42,711 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 10:30:42,714 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:30:42,714 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:30:42,714 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:30:42,714 [Thread-32] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,714 [Thread-32] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,714 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 10:30:42,716 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 10:30:42,717 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local764858715_0004_m_000000_0\n",
      "2024-02-15 10:30:42,720 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,720 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,720 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:42,721 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 224\n",
      "Input split[0]:\n",
      "   Length = 224\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:30:42,722 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1453782073/tmp-1569116790/part-r-00000:0+224\n",
      "2024-02-15 10:30:42,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:30:42,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:30:42,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:30:42,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:30:42,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:30:42,727 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:42,727 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:42,727 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: ordered_flights[36,18] C:  R: \n",
      "2024-02-15 10:30:42,728 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:30:42,728 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:30:42,728 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:30:42,728 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 224; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,728 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-15 10:30:42,732 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:30:42,732 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local764858715_0004_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:42,733 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:30:42,733 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local764858715_0004_m_000000_0' done.\n",
      "2024-02-15 10:30:42,733 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local764858715_0004_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107074\n",
      "\t\tFILE: Number of bytes written=2496849\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=224\n",
      "\t\tMap output materialized bytes=86\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=16\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=744488960\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:30:42,733 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local764858715_0004_m_000000_0\n",
      "2024-02-15 10:30:42,733 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 10:30:42,734 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 10:30:42,734 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local764858715_0004_r_000000_0\n",
      "2024-02-15 10:30:42,737 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,737 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,738 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:42,738 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1382ad26\n",
      "2024-02-15 10:30:42,738 [pool-15-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,739 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 10:30:42,739 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local764858715_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 10:30:42,740 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local764858715_0004_m_000000_0 decomp: 82 len: 86 to MEMORY\n",
      "2024-02-15 10:30:42,740 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 82 bytes from map-output for attempt_local764858715_0004_m_000000_0\n",
      "2024-02-15 10:30:42,740 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 82, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->82\n",
      "2024-02-15 10:30:42,740 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 10:30:42,740 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:30:42,740 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 10:30:42,741 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:30:42,741 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
      "2024-02-15 10:30:42,741 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 82 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 10:30:42,742 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 86 bytes from disk\n",
      "2024-02-15 10:30:42,742 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 10:30:42,742 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:30:42,742 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
      "2024-02-15 10:30:42,742 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:30:42,743 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,743 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,743 [pool-15-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:42,743 [pool-15-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:42,744 [pool-15-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: ordered_flights[36,18] C:  R: \n",
      "2024-02-15 10:30:42,744 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local764858715_0004_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:42,745 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:30:42,745 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local764858715_0004_r_000000_0 is allowed to commit now\n",
      "2024-02-15 10:30:42,746 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local764858715_0004_r_000000_0' to file:/tmp/temp1453782073/tmp1517668204\n",
      "2024-02-15 10:30:42,747 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 10:30:42,747 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local764858715_0004_r_000000_0' done.\n",
      "2024-02-15 10:30:42,747 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local764858715_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107278\n",
      "\t\tFILE: Number of bytes written=2497017\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=86\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=744488960\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 10:30:42,747 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local764858715_0004_r_000000_0\n",
      "2024-02-15 10:30:42,747 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:30:42,911 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local764858715_0004\n",
      "2024-02-15 10:30:42,911 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases ordered_flights\n",
      "2024-02-15 10:30:42,911 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: ordered_flights[36,18] C:  R: \n",
      "2024-02-15 10:30:42,912 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 80% complete\n",
      "2024-02-15 10:30:42,912 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,913 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,914 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,916 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 10:30:42,916 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 10:30:42,916 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 10:30:42,916 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 10:30:42,917 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 10:30:42,922 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 10:30:42,923 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,925 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 10:30:42,926 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:30:42,926 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 10:30:42,927 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 10:30:42,927 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-15 10:30:42,931 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local408125882_0005\n",
      "2024-02-15 10:30:42,931 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 10:30:42,970 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 10:30:42,970 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 10:30:42,973 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 10:30:42,973 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 10:30:42,973 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 10:30:42,973 [Thread-39] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,973 [Thread-39] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,973 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 10:30:42,975 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 10:30:42,975 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local408125882_0005_m_000000_0\n",
      "2024-02-15 10:30:42,979 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,979 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,979 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:42,979 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 70\n",
      "Input split[0]:\n",
      "   Length = 70\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 10:30:42,980 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1453782073/tmp1517668204/part-r-00000:0+70\n",
      "2024-02-15 10:30:42,984 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 10:30:42,984 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 10:30:42,984 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 10:30:42,984 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,984 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 10:30:42,984 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 10:30:42,985 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:42,985 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:42,985 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: ordered_flights[36,18] C:  R: \n",
      "2024-02-15 10:30:42,986 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 10:30:42,986 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 10:30:42,986 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 10:30:42,986 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 70; bufvoid = 104857600\n",
      "2024-02-15 10:30:42,986 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2024-02-15 10:30:42,986 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 10:30:42,987 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local408125882_0005_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:42,987 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 10:30:42,987 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local408125882_0005_m_000000_0' done.\n",
      "2024-02-15 10:30:42,987 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local408125882_0005_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107796\n",
      "\t\tFILE: Number of bytes written=3104706\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=70\n",
      "\t\tMap output materialized bytes=86\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=744488960\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 10:30:42,987 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local408125882_0005_m_000000_0\n",
      "2024-02-15 10:30:42,988 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 10:30:42,988 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 10:30:42,988 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local408125882_0005_r_000000_0\n",
      "2024-02-15 10:30:42,991 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,991 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,992 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 10:30:42,992 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@77f3af8b\n",
      "2024-02-15 10:30:42,992 [pool-18-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:42,993 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 10:30:42,993 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local408125882_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 10:30:42,994 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#5 about to shuffle output of map attempt_local408125882_0005_m_000000_0 decomp: 82 len: 86 to MEMORY\n",
      "2024-02-15 10:30:42,994 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 82 bytes from map-output for attempt_local408125882_0005_m_000000_0\n",
      "2024-02-15 10:30:42,994 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 82, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->82\n",
      "2024-02-15 10:30:42,994 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 10:30:42,994 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:30:42,994 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 10:30:42,995 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:30:42,995 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
      "2024-02-15 10:30:42,995 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 82 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 10:30:42,995 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 86 bytes from disk\n",
      "2024-02-15 10:30:42,995 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 10:30:42,995 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 10:30:42,996 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
      "2024-02-15 10:30:42,996 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:30:42,996 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 10:30:42,996 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 10:30:42,997 [pool-18-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 10:30:42,997 [pool-18-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:42,998 [pool-18-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: ordered_flights[36,18] C:  R: \n",
      "2024-02-15 10:30:42,998 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local408125882_0005_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 10:30:42,999 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 10:30:42,999 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local408125882_0005_r_000000_0 is allowed to commit now\n",
      "2024-02-15 10:30:43,000 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local408125882_0005_r_000000_0' to file:/tmp/temp1453782073/tmp1165511094\n",
      "2024-02-15 10:30:43,001 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 10:30:43,001 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local408125882_0005_r_000000_0' done.\n",
      "2024-02-15 10:30:43,001 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local408125882_0005_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72108000\n",
      "\t\tFILE: Number of bytes written=3104874\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=86\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=744488960\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 10:30:43,001 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local408125882_0005_r_000000_0\n",
      "2024-02-15 10:30:43,001 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:30:43,170 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local408125882_0005\n",
      "2024-02-15 10:30:43,170 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases ordered_flights\n",
      "2024-02-15 10:30:43,170 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: ordered_flights[36,18] C:  R: \n",
      "2024-02-15 10:30:43,171 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,172 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,173 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,175 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2024-02-15 10:30:43,178 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.3.1\t0.17.0\troot\t2024-02-15 10:30:33\t2024-02-15 10:30:43\tHASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local1079352555_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tordered_flights\tSAMPLER\t\n",
      "job_local1254809559_0002\t2\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tjoined_counts,percent_recovered\tHASH_JOIN\t\n",
      "job_local1659756285_0001\t3\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tdelayed_count,delayed_flights,flights_data,grouped_delayed_flights,grouped_recovered_flights,recovered_count,recovered_flights\tMULTI_QUERY,COMBINER\t\n",
      "job_local408125882_0005\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tordered_flights\t\tfile:/tmp/temp1453782073/tmp1165511094,\n",
      "job_local764858715_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tordered_flights\tORDER_BY,COMBINER\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/TAREA03/notebooks/flights.csv\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 5 records in: \"file:/tmp/temp1453782073/tmp1165511094\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 5\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local1659756285_0001\t->\tjob_local1254809559_0002,\n",
      "job_local1254809559_0002\t->\tjob_local1079352555_0003,\n",
      "job_local1079352555_0003\t->\tjob_local764858715_0004,\n",
      "job_local764858715_0004\t->\tjob_local408125882_0005,\n",
      "job_local408125882_0005\n",
      "\n",
      "\n",
      "2024-02-15 10:30:43,178 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,179 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,179 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,182 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,183 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,183 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,185 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,186 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,186 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,188 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,189 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,189 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,191 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,191 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,192 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 10:30:43,192 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2024-02-15 10:30:43,194 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 10:30:43,195 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 10:30:43,195 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(UA,0.245073)\n",
      "(WN,0.23570879)\n",
      "(FL,0.22657289)\n",
      "(DL,0.21578781)\n",
      "(AA,0.20162015)\n",
      "2024-02-15 10:30:43,229 [main] INFO  org.apache.pig.Main - Pig script completed in 10 seconds and 518 milliseconds (10518 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f recovery.pig  -param flights_file='flights.csv' -param output_dir='pig/output/percent_recovered'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
